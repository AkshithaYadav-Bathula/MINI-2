{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "id": "k-_rZPdT_nAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e57ac4-2c96-402a-97ed-91cf53dd5e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.162-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.162-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.162 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYdn1woOS1n",
        "outputId": "71686b8f-19ee-4821-937e-b7e85ba9023e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 74.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 400.8ms\n",
            "Speed: 23.5ms preprocess, 400.8ms inference, 32.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 331.7ms\n",
            "Speed: 14.1ms preprocess, 331.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 169.5ms\n",
            "Speed: 6.0ms preprocess, 169.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 167.8ms\n",
            "Speed: 6.0ms preprocess, 167.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 176.4ms\n",
            "Speed: 5.4ms preprocess, 176.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 174.3ms\n",
            "Speed: 5.9ms preprocess, 174.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 166.2ms\n",
            "Speed: 4.5ms preprocess, 166.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 162.2ms\n",
            "Speed: 6.5ms preprocess, 162.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 173.4ms\n",
            "Speed: 4.9ms preprocess, 173.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 166.7ms\n",
            "Speed: 6.0ms preprocess, 166.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 157.0ms\n",
            "Speed: 4.4ms preprocess, 157.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 178.0ms\n",
            "Speed: 6.2ms preprocess, 178.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 180.7ms\n",
            "Speed: 4.1ms preprocess, 180.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 175.2ms\n",
            "Speed: 4.1ms preprocess, 175.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 159.1ms\n",
            "Speed: 5.3ms preprocess, 159.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 171.8ms\n",
            "Speed: 4.4ms preprocess, 171.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 247.0ms\n",
            "Speed: 13.1ms preprocess, 247.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 262.2ms\n",
            "Speed: 4.3ms preprocess, 262.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 250.2ms\n",
            "Speed: 4.4ms preprocess, 250.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 189.9ms\n",
            "Speed: 4.4ms preprocess, 189.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 172.9ms\n",
            "Speed: 4.4ms preprocess, 172.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 159.6ms\n",
            "Speed: 5.4ms preprocess, 159.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 164.0ms\n",
            "Speed: 6.1ms preprocess, 164.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 179.5ms\n",
            "Speed: 5.2ms preprocess, 179.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 168.2ms\n",
            "Speed: 5.0ms preprocess, 168.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 160.1ms\n",
            "Speed: 4.4ms preprocess, 160.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 161.3ms\n",
            "Speed: 5.3ms preprocess, 161.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 tennis racket, 1 laptop, 188.7ms\n",
            "Speed: 4.4ms preprocess, 188.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bench, 1 backpack, 1 tennis racket, 1 laptop, 164.1ms\n",
            "Speed: 4.4ms preprocess, 164.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bench, 1 backpack, 1 tennis racket, 1 laptop, 158.5ms\n",
            "Speed: 4.4ms preprocess, 158.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bench, 1 backpack, 1 tennis racket, 1 laptop, 174.0ms\n",
            "Speed: 4.6ms preprocess, 174.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bench, 1 backpack, 1 tennis racket, 1 laptop, 174.6ms\n",
            "Speed: 5.6ms preprocess, 174.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 tennis racket, 1 laptop, 168.0ms\n",
            "Speed: 4.2ms preprocess, 168.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 tennis racket, 1 laptop, 161.3ms\n",
            "Speed: 4.0ms preprocess, 161.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 257.3ms\n",
            "Speed: 5.1ms preprocess, 257.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 287.0ms\n",
            "Speed: 4.0ms preprocess, 287.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 tennis racket, 1 laptop, 256.4ms\n",
            "Speed: 4.2ms preprocess, 256.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 166.9ms\n",
            "Speed: 4.2ms preprocess, 166.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 tennis racket, 1 laptop, 156.8ms\n",
            "Speed: 7.0ms preprocess, 156.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 tennis racket, 1 laptop, 169.9ms\n",
            "Speed: 4.4ms preprocess, 169.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 193.5ms\n",
            "Speed: 4.9ms preprocess, 193.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 162.4ms\n",
            "Speed: 5.1ms preprocess, 162.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 162.6ms\n",
            "Speed: 4.3ms preprocess, 162.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 190.3ms\n",
            "Speed: 4.3ms preprocess, 190.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 175.7ms\n",
            "Speed: 4.1ms preprocess, 175.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 162.4ms\n",
            "Speed: 4.4ms preprocess, 162.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 165.3ms\n",
            "Speed: 5.5ms preprocess, 165.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bench, 1 backpack, 1 laptop, 172.8ms\n",
            "Speed: 4.7ms preprocess, 172.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bench, 1 backpack, 1 laptop, 184.8ms\n",
            "Speed: 5.9ms preprocess, 184.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bench, 1 backpack, 1 laptop, 159.7ms\n",
            "Speed: 4.5ms preprocess, 159.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bench, 1 laptop, 161.2ms\n",
            "Speed: 4.3ms preprocess, 161.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 bench, 1 laptop, 190.2ms\n",
            "Speed: 4.3ms preprocess, 190.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 bench, 1 laptop, 193.7ms\n",
            "Speed: 5.2ms preprocess, 193.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 260.6ms\n",
            "Speed: 5.8ms preprocess, 260.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 246.8ms\n",
            "Speed: 11.4ms preprocess, 246.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 bench, 1 laptop, 235.5ms\n",
            "Speed: 8.2ms preprocess, 235.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 167.6ms\n",
            "Speed: 5.1ms preprocess, 167.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 157.1ms\n",
            "Speed: 5.0ms preprocess, 157.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 164.1ms\n",
            "Speed: 4.2ms preprocess, 164.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 174.3ms\n",
            "Speed: 4.4ms preprocess, 174.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 167.9ms\n",
            "Speed: 5.5ms preprocess, 167.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 176.2ms\n",
            "Speed: 4.2ms preprocess, 176.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 161.2ms\n",
            "Speed: 5.0ms preprocess, 161.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 178.1ms\n",
            "Speed: 4.5ms preprocess, 178.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 169.9ms\n",
            "Speed: 4.4ms preprocess, 169.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 155.9ms\n",
            "Speed: 6.0ms preprocess, 155.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 159.8ms\n",
            "Speed: 5.9ms preprocess, 159.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 172.9ms\n",
            "Speed: 3.9ms preprocess, 172.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 162.5ms\n",
            "Speed: 4.0ms preprocess, 162.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 175.2ms\n",
            "Speed: 5.2ms preprocess, 175.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 158.9ms\n",
            "Speed: 4.4ms preprocess, 158.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 238.9ms\n",
            "Speed: 17.5ms preprocess, 238.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 247.9ms\n",
            "Speed: 10.6ms preprocess, 247.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 289.0ms\n",
            "Speed: 4.4ms preprocess, 289.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 179.9ms\n",
            "Speed: 4.4ms preprocess, 179.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 166.1ms\n",
            "Speed: 4.5ms preprocess, 166.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 159.1ms\n",
            "Speed: 4.3ms preprocess, 159.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 173.8ms\n",
            "Speed: 5.1ms preprocess, 173.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 160.3ms\n",
            "Speed: 4.3ms preprocess, 160.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 222.2ms\n",
            "Speed: 4.2ms preprocess, 222.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 173.0ms\n",
            "Speed: 4.4ms preprocess, 173.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 168.5ms\n",
            "Speed: 5.5ms preprocess, 168.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 165.0ms\n",
            "Speed: 4.4ms preprocess, 165.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 174.5ms\n",
            "Speed: 4.5ms preprocess, 174.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 169.4ms\n",
            "Speed: 4.2ms preprocess, 169.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 164.3ms\n",
            "Speed: 4.5ms preprocess, 164.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 161.5ms\n",
            "Speed: 5.0ms preprocess, 161.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 190.7ms\n",
            "Speed: 4.9ms preprocess, 190.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 166.4ms\n",
            "Speed: 5.7ms preprocess, 166.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 270.4ms\n",
            "Speed: 4.6ms preprocess, 270.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 238.4ms\n",
            "Speed: 4.4ms preprocess, 238.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 260.7ms\n",
            "Speed: 4.3ms preprocess, 260.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 167.3ms\n",
            "Speed: 4.2ms preprocess, 167.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 159.1ms\n",
            "Speed: 4.4ms preprocess, 159.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 161.7ms\n",
            "Speed: 4.4ms preprocess, 161.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 170.9ms\n",
            "Speed: 4.5ms preprocess, 170.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 165.5ms\n",
            "Speed: 4.5ms preprocess, 165.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 171.2ms\n",
            "Speed: 4.2ms preprocess, 171.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 161.8ms\n",
            "Speed: 4.3ms preprocess, 161.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 170.9ms\n",
            "Speed: 4.4ms preprocess, 170.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 163.7ms\n",
            "Speed: 4.5ms preprocess, 163.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 156.8ms\n",
            "Speed: 4.2ms preprocess, 156.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 173.3ms\n",
            "Speed: 4.2ms preprocess, 173.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 173.6ms\n",
            "Speed: 4.4ms preprocess, 173.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 bench, 1 handbag, 1 laptop, 170.5ms\n",
            "Speed: 4.3ms preprocess, 170.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 173.8ms\n",
            "Speed: 4.4ms preprocess, 173.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 bench, 1 laptop, 159.6ms\n",
            "Speed: 5.3ms preprocess, 159.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 218.6ms\n",
            "Speed: 4.2ms preprocess, 218.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 283.3ms\n",
            "Speed: 4.4ms preprocess, 283.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 303.1ms\n",
            "Speed: 4.4ms preprocess, 303.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 178.2ms\n",
            "Speed: 4.2ms preprocess, 178.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 bench, 1 laptop, 175.6ms\n",
            "Speed: 4.4ms preprocess, 175.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 164.0ms\n",
            "Speed: 6.3ms preprocess, 164.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 bench, 1 laptop, 156.1ms\n",
            "Speed: 6.1ms preprocess, 156.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 165.7ms\n",
            "Speed: 4.5ms preprocess, 165.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 laptop, 187.9ms\n",
            "Speed: 4.8ms preprocess, 187.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 163.5ms\n",
            "Speed: 4.5ms preprocess, 163.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 159.4ms\n",
            "Speed: 4.5ms preprocess, 159.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 160.8ms\n",
            "Speed: 4.3ms preprocess, 160.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 172.5ms\n",
            "Speed: 4.0ms preprocess, 172.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 160.5ms\n",
            "Speed: 4.5ms preprocess, 160.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 laptop, 155.1ms\n",
            "Speed: 4.3ms preprocess, 155.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 laptop, 157.8ms\n",
            "Speed: 4.3ms preprocess, 157.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 laptop, 189.3ms\n",
            "Speed: 5.9ms preprocess, 189.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 laptop, 170.2ms\n",
            "Speed: 4.2ms preprocess, 170.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 laptop, 154.1ms\n",
            "Speed: 4.4ms preprocess, 154.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 laptop, 261.4ms\n",
            "Speed: 4.3ms preprocess, 261.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 305.9ms\n",
            "Speed: 4.3ms preprocess, 305.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 251.6ms\n",
            "Speed: 4.4ms preprocess, 251.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 159.8ms\n",
            "Speed: 4.5ms preprocess, 159.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 157.9ms\n",
            "Speed: 4.3ms preprocess, 157.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 handbag, 1 laptop, 174.1ms\n",
            "Speed: 4.5ms preprocess, 174.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 handbag, 1 laptop, 176.7ms\n",
            "Speed: 8.6ms preprocess, 176.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 handbag, 1 laptop, 156.2ms\n",
            "Speed: 5.0ms preprocess, 156.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 158.7ms\n",
            "Speed: 4.3ms preprocess, 158.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 handbag, 1 laptop, 175.9ms\n",
            "Speed: 4.3ms preprocess, 175.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 184.7ms\n",
            "Speed: 5.1ms preprocess, 184.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 handbag, 1 laptop, 157.1ms\n",
            "Speed: 4.3ms preprocess, 157.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 1 laptop, 165.7ms\n",
            "Speed: 8.3ms preprocess, 165.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 backpack, 1 handbag, 1 laptop, 187.0ms\n",
            "Speed: 4.3ms preprocess, 187.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 167.0ms\n",
            "Speed: 3.9ms preprocess, 167.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 163.4ms\n",
            "Speed: 4.6ms preprocess, 163.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 handbag, 1 laptop, 162.7ms\n",
            "Speed: 4.6ms preprocess, 162.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 171.7ms\n",
            "Speed: 4.1ms preprocess, 171.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 241.9ms\n",
            "Speed: 6.8ms preprocess, 241.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 262.9ms\n",
            "Speed: 5.4ms preprocess, 262.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 301.7ms\n",
            "Speed: 8.6ms preprocess, 301.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 159.5ms\n",
            "Speed: 4.3ms preprocess, 159.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 163.6ms\n",
            "Speed: 4.7ms preprocess, 163.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 199.6ms\n",
            "Speed: 4.6ms preprocess, 199.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 handbag, 1 laptop, 169.0ms\n",
            "Speed: 4.7ms preprocess, 169.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 165.7ms\n",
            "Speed: 4.2ms preprocess, 165.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 159.2ms\n",
            "Speed: 4.3ms preprocess, 159.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 176.4ms\n",
            "Speed: 4.4ms preprocess, 176.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 1 laptop, 165.2ms\n",
            "Speed: 5.1ms preprocess, 165.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 1 laptop, 162.8ms\n",
            "Speed: 4.5ms preprocess, 162.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 154.0ms\n",
            "Speed: 4.3ms preprocess, 154.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 handbag, 1 laptop, 186.8ms\n",
            "Speed: 4.4ms preprocess, 186.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 handbag, 1 laptop, 162.9ms\n",
            "Speed: 4.2ms preprocess, 162.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 backpack, 1 handbag, 1 laptop, 157.4ms\n",
            "Speed: 4.4ms preprocess, 157.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 handbag, 1 laptop, 169.1ms\n",
            "Speed: 4.6ms preprocess, 169.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 157.4ms\n",
            "Speed: 4.3ms preprocess, 157.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 257.3ms\n",
            "Speed: 12.2ms preprocess, 257.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 297.4ms\n",
            "Speed: 4.4ms preprocess, 297.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 271.3ms\n",
            "Speed: 4.2ms preprocess, 271.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 162.0ms\n",
            "Speed: 5.1ms preprocess, 162.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 170.2ms\n",
            "Speed: 5.6ms preprocess, 170.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 189.7ms\n",
            "Speed: 4.4ms preprocess, 189.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 168.3ms\n",
            "Speed: 4.4ms preprocess, 168.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 1 book, 162.4ms\n",
            "Speed: 4.1ms preprocess, 162.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 1 laptop, 164.5ms\n",
            "Speed: 5.1ms preprocess, 164.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 182.8ms\n",
            "Speed: 4.9ms preprocess, 182.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 171.3ms\n",
            "Speed: 5.6ms preprocess, 171.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 159.9ms\n",
            "Speed: 4.9ms preprocess, 159.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 161.3ms\n",
            "Speed: 4.6ms preprocess, 161.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 189.7ms\n",
            "Speed: 4.4ms preprocess, 189.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 167.0ms\n",
            "Speed: 6.0ms preprocess, 167.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 159.9ms\n",
            "Speed: 4.3ms preprocess, 159.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 157.8ms\n",
            "Speed: 4.3ms preprocess, 157.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 170.0ms\n",
            "Speed: 4.4ms preprocess, 170.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 1 laptop, 260.8ms\n",
            "Speed: 7.7ms preprocess, 260.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 268.2ms\n",
            "Speed: 4.4ms preprocess, 268.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 1 laptop, 274.8ms\n",
            "Speed: 6.1ms preprocess, 274.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 1 laptop, 197.3ms\n",
            "Speed: 4.4ms preprocess, 197.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 handbag, 1 laptop, 167.1ms\n",
            "Speed: 4.6ms preprocess, 167.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 176.4ms\n",
            "Speed: 7.1ms preprocess, 176.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 184.5ms\n",
            "Speed: 4.5ms preprocess, 184.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 174.4ms\n",
            "Speed: 4.9ms preprocess, 174.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 182.1ms\n",
            "Speed: 4.3ms preprocess, 182.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 159.2ms\n",
            "Speed: 4.2ms preprocess, 159.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 160.4ms\n",
            "Speed: 4.1ms preprocess, 160.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 175.5ms\n",
            "Speed: 5.4ms preprocess, 175.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 160.2ms\n",
            "Speed: 4.5ms preprocess, 160.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 177.7ms\n",
            "Speed: 4.5ms preprocess, 177.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 163.2ms\n",
            "Speed: 6.4ms preprocess, 163.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 174.1ms\n",
            "Speed: 4.3ms preprocess, 174.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 181.4ms\n",
            "Speed: 4.2ms preprocess, 181.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 159.4ms\n",
            "Speed: 4.2ms preprocess, 159.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 158.3ms\n",
            "Speed: 4.0ms preprocess, 158.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 290.6ms\n",
            "Speed: 6.8ms preprocess, 290.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 260.4ms\n",
            "Speed: 4.3ms preprocess, 260.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 1 laptop, 1 book, 245.3ms\n",
            "Speed: 4.5ms preprocess, 245.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 162.6ms\n",
            "Speed: 5.1ms preprocess, 162.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 171.5ms\n",
            "Speed: 4.5ms preprocess, 171.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 164.0ms\n",
            "Speed: 4.5ms preprocess, 164.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 162.7ms\n",
            "Speed: 4.3ms preprocess, 162.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 175.9ms\n",
            "Speed: 4.4ms preprocess, 175.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 171.5ms\n",
            "Speed: 4.4ms preprocess, 171.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 174.5ms\n",
            "Speed: 4.4ms preprocess, 174.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 167.2ms\n",
            "Speed: 4.7ms preprocess, 167.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 1 book, 156.7ms\n",
            "Speed: 4.4ms preprocess, 156.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 179.0ms\n",
            "Speed: 4.4ms preprocess, 179.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 1 book, 165.0ms\n",
            "Speed: 4.4ms preprocess, 165.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 158.1ms\n",
            "Speed: 4.7ms preprocess, 158.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 186.7ms\n",
            "Speed: 5.5ms preprocess, 186.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 175.7ms\n",
            "Speed: 4.5ms preprocess, 175.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 159.4ms\n",
            "Speed: 4.2ms preprocess, 159.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 1 laptop, 1 book, 265.6ms\n",
            "Speed: 10.0ms preprocess, 265.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 295.0ms\n",
            "Speed: 13.2ms preprocess, 295.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 1 book, 274.6ms\n",
            "Speed: 4.8ms preprocess, 274.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 1 book, 164.3ms\n",
            "Speed: 5.5ms preprocess, 164.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 182.3ms\n",
            "Speed: 4.5ms preprocess, 182.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 265.7ms\n",
            "Speed: 4.3ms preprocess, 265.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 267.7ms\n",
            "Speed: 4.5ms preprocess, 267.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 262.1ms\n",
            "Speed: 4.4ms preprocess, 262.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 179.5ms\n",
            "Speed: 7.0ms preprocess, 179.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 165.2ms\n",
            "Speed: 4.4ms preprocess, 165.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 188.7ms\n",
            "Speed: 4.6ms preprocess, 188.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 159.5ms\n",
            "Speed: 4.4ms preprocess, 159.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 158.3ms\n",
            "Speed: 4.3ms preprocess, 158.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 173.0ms\n",
            "Speed: 4.5ms preprocess, 173.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 168.5ms\n",
            "Speed: 4.6ms preprocess, 168.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 handbag, 1 laptop, 1 book, 183.2ms\n",
            "Speed: 4.4ms preprocess, 183.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 159.0ms\n",
            "Speed: 4.4ms preprocess, 159.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 2 books, 303.3ms\n",
            "Speed: 5.3ms preprocess, 303.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 241.9ms\n",
            "Speed: 10.3ms preprocess, 241.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 2 books, 240.6ms\n",
            "Speed: 9.5ms preprocess, 240.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 174.6ms\n",
            "Speed: 4.4ms preprocess, 174.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 173.6ms\n",
            "Speed: 6.6ms preprocess, 173.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 170.0ms\n",
            "Speed: 4.2ms preprocess, 170.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 159.6ms\n",
            "Speed: 4.3ms preprocess, 159.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 161.1ms\n",
            "Speed: 4.1ms preprocess, 161.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 176.9ms\n",
            "Speed: 4.4ms preprocess, 176.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 168.8ms\n",
            "Speed: 4.6ms preprocess, 168.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 155.5ms\n",
            "Speed: 4.3ms preprocess, 155.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 161.4ms\n",
            "Speed: 5.0ms preprocess, 161.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 175.0ms\n",
            "Speed: 5.2ms preprocess, 175.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 163.6ms\n",
            "Speed: 4.4ms preprocess, 163.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 173.4ms\n",
            "Speed: 4.4ms preprocess, 173.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 176.9ms\n",
            "Speed: 6.2ms preprocess, 176.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 165.1ms\n",
            "Speed: 11.6ms preprocess, 165.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 179.3ms\n",
            "Speed: 5.8ms preprocess, 179.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 294.2ms\n",
            "Speed: 10.8ms preprocess, 294.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 266.3ms\n",
            "Speed: 4.5ms preprocess, 266.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 241.8ms\n",
            "Speed: 5.8ms preprocess, 241.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 183.7ms\n",
            "Speed: 4.5ms preprocess, 183.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 178.7ms\n",
            "Speed: 4.4ms preprocess, 178.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 164.0ms\n",
            "Speed: 6.1ms preprocess, 164.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 168.5ms\n",
            "Speed: 5.0ms preprocess, 168.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 190.8ms\n",
            "Speed: 4.4ms preprocess, 190.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 165.3ms\n",
            "Speed: 4.3ms preprocess, 165.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 158.2ms\n",
            "Speed: 5.3ms preprocess, 158.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 156.9ms\n",
            "Speed: 4.3ms preprocess, 156.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 180.9ms\n",
            "Speed: 5.1ms preprocess, 180.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 164.3ms\n",
            "Speed: 4.1ms preprocess, 164.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 161.4ms\n",
            "Speed: 4.3ms preprocess, 161.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 161.0ms\n",
            "Speed: 4.3ms preprocess, 161.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 197.0ms\n",
            "Speed: 4.7ms preprocess, 197.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 168.7ms\n",
            "Speed: 4.6ms preprocess, 168.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 233.3ms\n",
            "Speed: 5.0ms preprocess, 233.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 265.9ms\n",
            "Speed: 4.4ms preprocess, 265.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 275.4ms\n",
            "Speed: 7.7ms preprocess, 275.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 181.8ms\n",
            "Speed: 4.3ms preprocess, 181.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 160.4ms\n",
            "Speed: 5.4ms preprocess, 160.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 166.2ms\n",
            "Speed: 4.4ms preprocess, 166.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 190.6ms\n",
            "Speed: 4.4ms preprocess, 190.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 160.5ms\n",
            "Speed: 6.4ms preprocess, 160.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 162.9ms\n",
            "Speed: 4.5ms preprocess, 162.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 161.0ms\n",
            "Speed: 4.4ms preprocess, 161.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 175.6ms\n",
            "Speed: 4.3ms preprocess, 175.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 192.8ms\n",
            "Speed: 4.4ms preprocess, 192.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 155.7ms\n",
            "Speed: 4.3ms preprocess, 155.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 159.8ms\n",
            "Speed: 5.1ms preprocess, 159.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 200.2ms\n",
            "Speed: 4.4ms preprocess, 200.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 165.3ms\n",
            "Speed: 4.3ms preprocess, 165.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 162.4ms\n",
            "Speed: 4.2ms preprocess, 162.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 161.8ms\n",
            "Speed: 4.6ms preprocess, 161.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 246.7ms\n",
            "Speed: 4.8ms preprocess, 246.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 274.6ms\n",
            "Speed: 7.4ms preprocess, 274.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 314.8ms\n",
            "Speed: 12.6ms preprocess, 314.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 161.5ms\n",
            "Speed: 4.3ms preprocess, 161.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 174.2ms\n",
            "Speed: 6.0ms preprocess, 174.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 173.4ms\n",
            "Speed: 4.2ms preprocess, 173.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 168.3ms\n",
            "Speed: 8.3ms preprocess, 168.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 163.5ms\n",
            "Speed: 4.3ms preprocess, 163.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 176.6ms\n",
            "Speed: 4.8ms preprocess, 176.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 177.4ms\n",
            "Speed: 4.5ms preprocess, 177.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 159.6ms\n",
            "Speed: 4.4ms preprocess, 159.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 185.9ms\n",
            "Speed: 4.4ms preprocess, 185.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 167.7ms\n",
            "Speed: 4.4ms preprocess, 167.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 166.3ms\n",
            "Speed: 4.9ms preprocess, 166.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 177.7ms\n",
            "Speed: 4.5ms preprocess, 177.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 169.1ms\n",
            "Speed: 4.2ms preprocess, 169.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 163.2ms\n",
            "Speed: 4.5ms preprocess, 163.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 178.9ms\n",
            "Speed: 4.3ms preprocess, 178.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 handbag, 1 laptop, 1 book, 216.1ms\n",
            "Speed: 4.4ms preprocess, 216.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 264.1ms\n",
            "Speed: 7.3ms preprocess, 264.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 251.6ms\n",
            "Speed: 4.4ms preprocess, 251.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 251.3ms\n",
            "Speed: 11.6ms preprocess, 251.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 193.2ms\n",
            "Speed: 4.5ms preprocess, 193.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 164.3ms\n",
            "Speed: 5.5ms preprocess, 164.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 168.5ms\n",
            "Speed: 4.1ms preprocess, 168.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 162.8ms\n",
            "Speed: 5.7ms preprocess, 162.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 174.5ms\n",
            "Speed: 4.4ms preprocess, 174.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 165.1ms\n",
            "Speed: 5.2ms preprocess, 165.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 160.4ms\n",
            "Speed: 5.2ms preprocess, 160.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 157.7ms\n",
            "Speed: 5.8ms preprocess, 157.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 193.1ms\n",
            "Speed: 4.5ms preprocess, 193.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 1 laptop, 1 book, 170.0ms\n",
            "Speed: 5.3ms preprocess, 170.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 158.0ms\n",
            "Speed: 4.3ms preprocess, 158.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 153.6ms\n",
            "Speed: 4.6ms preprocess, 153.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 174.9ms\n",
            "Speed: 5.4ms preprocess, 174.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 1 book, 165.5ms\n",
            "Speed: 4.4ms preprocess, 165.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 1 book, 182.2ms\n",
            "Speed: 4.3ms preprocess, 182.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 1 book, 240.7ms\n",
            "Speed: 5.4ms preprocess, 240.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 288.3ms\n",
            "Speed: 4.5ms preprocess, 288.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 288.7ms\n",
            "Speed: 7.3ms preprocess, 288.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 161.9ms\n",
            "Speed: 4.2ms preprocess, 161.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 160.7ms\n",
            "Speed: 4.5ms preprocess, 160.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 176.3ms\n",
            "Speed: 4.5ms preprocess, 176.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 176.4ms\n",
            "Speed: 4.3ms preprocess, 176.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 157.2ms\n",
            "Speed: 4.3ms preprocess, 157.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 183.5ms\n",
            "Speed: 4.4ms preprocess, 183.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 164.5ms\n",
            "Speed: 4.3ms preprocess, 164.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 1 book, 166.3ms\n",
            "Speed: 4.4ms preprocess, 166.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 164.9ms\n",
            "Speed: 4.4ms preprocess, 164.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 172.9ms\n",
            "Speed: 4.6ms preprocess, 172.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 1 book, 165.9ms\n",
            "Speed: 4.4ms preprocess, 165.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 188.4ms\n",
            "Speed: 4.3ms preprocess, 188.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 1 book, 260.8ms\n",
            "Speed: 10.0ms preprocess, 260.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 laptop, 1 book, 276.3ms\n",
            "Speed: 17.5ms preprocess, 276.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 545.5ms\n",
            "Speed: 19.2ms preprocess, 545.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 479.8ms\n",
            "Speed: 13.2ms preprocess, 479.8ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 1 book, 279.2ms\n",
            "Speed: 4.5ms preprocess, 279.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 176.7ms\n",
            "Speed: 6.3ms preprocess, 176.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 172.3ms\n",
            "Speed: 4.4ms preprocess, 172.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 184.1ms\n",
            "Speed: 5.6ms preprocess, 184.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 161.8ms\n",
            "Speed: 4.3ms preprocess, 161.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 1 book, 175.3ms\n",
            "Speed: 4.1ms preprocess, 175.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 laptop, 1 book, 179.6ms\n",
            "Speed: 4.4ms preprocess, 179.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 154.7ms\n",
            "Speed: 9.4ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 157.1ms\n",
            "Speed: 4.4ms preprocess, 157.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 182.4ms\n",
            "Speed: 4.1ms preprocess, 182.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 162.6ms\n",
            "Speed: 4.5ms preprocess, 162.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 171.9ms\n",
            "Speed: 4.7ms preprocess, 171.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 159.9ms\n",
            "Speed: 5.5ms preprocess, 159.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 176.0ms\n",
            "Speed: 4.6ms preprocess, 176.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 172.7ms\n",
            "Speed: 4.4ms preprocess, 172.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 156.7ms\n",
            "Speed: 4.2ms preprocess, 156.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 278.0ms\n",
            "Speed: 4.8ms preprocess, 278.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 281.1ms\n",
            "Speed: 4.5ms preprocess, 281.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 260.0ms\n",
            "Speed: 4.3ms preprocess, 260.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 158.2ms\n",
            "Speed: 4.4ms preprocess, 158.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 169.6ms\n",
            "Speed: 4.4ms preprocess, 169.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 171.1ms\n",
            "Speed: 4.6ms preprocess, 171.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 159.7ms\n",
            "Speed: 4.4ms preprocess, 159.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 171.0ms\n",
            "Speed: 4.2ms preprocess, 171.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 174.9ms\n",
            "Speed: 5.4ms preprocess, 174.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 171.2ms\n",
            "Speed: 4.8ms preprocess, 171.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 163.3ms\n",
            "Speed: 8.6ms preprocess, 163.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 178.7ms\n",
            "Speed: 4.8ms preprocess, 178.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 164.9ms\n",
            "Speed: 4.5ms preprocess, 164.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 1 book, 155.8ms\n",
            "Speed: 4.3ms preprocess, 155.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 1 book, 174.4ms\n",
            "Speed: 4.5ms preprocess, 174.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 1 book, 164.6ms\n",
            "Speed: 4.4ms preprocess, 164.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 1 book, 152.7ms\n",
            "Speed: 4.3ms preprocess, 152.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 laptop, 1 book, 238.5ms\n",
            "Speed: 5.2ms preprocess, 238.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 laptop, 1 book, 287.6ms\n",
            "Speed: 4.4ms preprocess, 287.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 286.6ms\n",
            "Speed: 12.5ms preprocess, 286.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 215.1ms\n",
            "Speed: 9.3ms preprocess, 215.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 182.9ms\n",
            "Speed: 4.4ms preprocess, 182.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 laptops, 1 book, 175.7ms\n",
            "Speed: 4.7ms preprocess, 175.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 laptops, 1 book, 161.4ms\n",
            "Speed: 5.8ms preprocess, 161.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 1 book, 161.8ms\n",
            "Speed: 5.8ms preprocess, 161.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 laptops, 1 book, 173.5ms\n",
            "Speed: 4.4ms preprocess, 173.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 1 book, 160.7ms\n",
            "Speed: 4.5ms preprocess, 160.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 1 book, 157.0ms\n",
            "Speed: 4.3ms preprocess, 157.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 1 book, 167.1ms\n",
            "Speed: 5.3ms preprocess, 167.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 171.5ms\n",
            "Speed: 4.4ms preprocess, 171.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 1 book, 168.3ms\n",
            "Speed: 4.4ms preprocess, 168.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 158.9ms\n",
            "Speed: 4.1ms preprocess, 158.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 164.0ms\n",
            "Speed: 6.3ms preprocess, 164.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 174.7ms\n",
            "Speed: 4.3ms preprocess, 174.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 167.8ms\n",
            "Speed: 5.5ms preprocess, 167.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 267.5ms\n",
            "Speed: 4.3ms preprocess, 267.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 laptops, 1 book, 264.8ms\n",
            "Speed: 6.1ms preprocess, 264.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 laptops, 1 book, 309.4ms\n",
            "Speed: 6.1ms preprocess, 309.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 laptop, 1 book, 164.9ms\n",
            "Speed: 4.5ms preprocess, 164.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 laptops, 159.6ms\n",
            "Speed: 4.5ms preprocess, 159.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 laptops, 172.5ms\n",
            "Speed: 4.3ms preprocess, 172.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 laptops, 173.0ms\n",
            "Speed: 4.4ms preprocess, 173.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 laptops, 1 book, 166.9ms\n",
            "Speed: 4.3ms preprocess, 166.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 laptops, 1 book, 172.7ms\n",
            "Speed: 4.2ms preprocess, 172.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 162.9ms\n",
            "Speed: 4.5ms preprocess, 162.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 172.6ms\n",
            "Speed: 4.6ms preprocess, 172.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 171.6ms\n",
            "Speed: 5.9ms preprocess, 171.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 160.7ms\n",
            "Speed: 4.5ms preprocess, 160.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 165.3ms\n",
            "Speed: 4.6ms preprocess, 165.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 171.7ms\n",
            "Speed: 4.4ms preprocess, 171.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 173.6ms\n",
            "Speed: 5.4ms preprocess, 173.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 laptop, 1 book, 163.9ms\n",
            "Speed: 4.4ms preprocess, 163.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 3 laptops, 1 book, 158.0ms\n",
            "Speed: 4.3ms preprocess, 158.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 laptops, 1 book, 259.6ms\n",
            "Speed: 4.4ms preprocess, 259.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 laptops, 1 book, 249.7ms\n",
            "Speed: 9.7ms preprocess, 249.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 276.5ms\n",
            "Speed: 4.3ms preprocess, 276.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 171.2ms\n",
            "Speed: 4.5ms preprocess, 171.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 173.7ms\n",
            "Speed: 4.4ms preprocess, 173.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 laptops, 1 book, 159.1ms\n",
            "Speed: 4.4ms preprocess, 159.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 161.5ms\n",
            "Speed: 4.4ms preprocess, 161.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 173.9ms\n",
            "Speed: 4.8ms preprocess, 173.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 168.1ms\n",
            "Speed: 4.5ms preprocess, 168.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 laptop, 1 book, 167.3ms\n",
            "Speed: 4.9ms preprocess, 167.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 188.0ms\n",
            "Speed: 4.7ms preprocess, 188.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 159.8ms\n",
            "Speed: 4.4ms preprocess, 159.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 155.4ms\n",
            "Speed: 4.6ms preprocess, 155.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 laptop, 1 book, 142.0ms\n",
            "Speed: 4.8ms preprocess, 142.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 laptop, 1 book, 141.0ms\n",
            "Speed: 5.1ms preprocess, 141.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 laptop, 1 book, 158.2ms\n",
            "Speed: 4.7ms preprocess, 158.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Extracted and saved 428 frames with detection overlays.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")  # Use your preferred weights\n",
        "\n",
        "# Video path\n",
        "video_path = \"/content/2.mp4\"\n",
        "output_frames_dir = \"frames\"\n",
        "os.makedirs(output_frames_dir, exist_ok=True)\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_num = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run YOLO detection\n",
        "    results = model(frame)\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Save annotated frame\n",
        "    frame_filename = os.path.join(output_frames_dir, f\"frame_{frame_num:05d}.png\")\n",
        "    cv2.imwrite(frame_filename, annotated_frame)\n",
        "\n",
        "    frame_num += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"Extracted and saved {frame_num} frames with detection overlays.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "frames_dir = \"frames\"  # Use your edited frames folder if you saved them separately\n",
        "output_video = \"output_video.mp4\"\n",
        "fps = 30  # Adjust to match your original video's FPS\n",
        "\n",
        "# Get frame list sorted\n",
        "frames = sorted([f for f in os.listdir(frames_dir) if f.endswith(\".png\")])\n",
        "frame_example = cv2.imread(os.path.join(frames_dir, frames[0]))\n",
        "height, width, _ = frame_example.shape\n",
        "\n",
        "# Setup video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
        "\n",
        "# Suppose you kept a list of frame numbers where you removed objects\n",
        "removed_object_frames = [59,60,61,62,63]  # Example, put your own list here\n",
        "\n",
        "for idx, frame_name in enumerate(frames):\n",
        "    frame = cv2.imread(os.path.join(frames_dir, frame_name))\n",
        "    out.write(frame)\n",
        "\n",
        "    if idx in removed_object_frames:\n",
        "        seconds = idx / fps\n",
        "        print(f\"⚠️ Object missing at frame {idx} → time {seconds:.2f} sec\")\n",
        "\n",
        "out.release()\n",
        "print(f\"✅ Video saved as {output_video}\")"
      ],
      "metadata": {
        "id": "ELFhZ7h1-6ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HASH CONVERSION FOR ORIGINAL IMAGE"
      ],
      "metadata": {
        "id": "LXWTdNTdGlRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def hash_video_file(file_path):\n",
        "    BUF_SIZE = 65536  # 64KB chunks\n",
        "    sha256 = hashlib.sha256()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        while True:\n",
        "            data = f.read(BUF_SIZE)\n",
        "            if not data:\n",
        "                break\n",
        "            sha256.update(data)\n",
        "    return sha256.hexdigest()\n",
        "\n",
        "video_hash = hash_video_file('/content/1.mp4')\n",
        "print(\"File hash:\", video_hash)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJr_uKp9GeX9",
        "outputId": "f4bccecb-1de4-49c9-f033-2aa91b4856c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File hash: 33ff7c2485e265bc7d4ee1c9f32eaf9afbaeb7bcba30b13baf144898bfb8c615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HASH FOR MASKED VIEO"
      ],
      "metadata": {
        "id": "yl9PcroZGsue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def hash_video_file(file_path):\n",
        "    BUF_SIZE = 65536  # 64KB chunks\n",
        "    sha256 = hashlib.sha256()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        while True:\n",
        "            data = f.read(BUF_SIZE)\n",
        "            if not data:\n",
        "                break\n",
        "            sha256.update(data)\n",
        "    return sha256.hexdigest()\n",
        "\n",
        "video_hash = hash_video_file('/content/masked video.mp4')\n",
        "print(\"File hash:\", video_hash)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akXmrcHvGrz2",
        "outputId": "59fb5c31-a256-46ad-fd95-af9fdf892a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File hash: 60e311f119104fd9c6222da804aaa1a903df9666d0be2d3bbbfbbec0132811d6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMPARE HASH"
      ],
      "metadata": {
        "id": "KaRotfYsG4mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def hash_video_file(file_path):\n",
        "    BUF_SIZE = 65536\n",
        "    sha256 = hashlib.sha256()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        while True:\n",
        "            data = f.read(BUF_SIZE)\n",
        "            if not data:\n",
        "                break\n",
        "            sha256.update(data)\n",
        "    return sha256.hexdigest()\n",
        "\n",
        "# Hash two video files\n",
        "hash1 = hash_video_file('/content/1.mp4')\n",
        "hash2 = hash_video_file('/content/masked video.mp4')\n",
        "\n",
        "print(\"Original hash:\", hash1)\n",
        "print(\"Suspect hash:\", hash2)\n",
        "\n",
        "if hash1 == hash2:\n",
        "    print(\"✅ MATCH: Original video.\")\n",
        "else:\n",
        "    print(\"❌ MISMATCH:Masked(fake) video.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IQ2ckfjG58z",
        "outputId": "976d93ca-cf27-4316-e8c3-440459e87ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original hash: 7f119862e5791ec6518e8df5fc87980fe9e4839924e5f8e6f8d99f3b02dd9352\n",
            "Suspect hash: e31b5c1caca235d9097662c4d686fa52be96fc12ca715f80597ba4bbb0b1a826\n",
            "❌ MISMATCH:Masked(fake) video.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def hash_video_file(file_path):\n",
        "    BUF_SIZE = 65536\n",
        "    sha256 = hashlib.sha256()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        while True:\n",
        "            data = f.read(BUF_SIZE)\n",
        "            if not data:\n",
        "                break\n",
        "            sha256.update(data)\n",
        "    return sha256.hexdigest()\n",
        "\n",
        "# Hash two video files\n",
        "hash1 = hash_video_file('/content/1.mp4')\n",
        "hash2 = hash_video_file('/content/1.mp4')\n",
        "\n",
        "print(\"Original hash:\", hash1)\n",
        "print(\"Suspect hash:\", hash2)\n",
        "\n",
        "if hash1 == hash2:\n",
        "    print(\"✅ MATCH: Videos are identical.\")\n",
        "else:\n",
        "    print(\"❌ MISMATCH: Videos are different.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4ViM39GHVzu",
        "outputId": "e38e06ac-4e50-48e8-8142-74e6b51021a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original hash: 7f119862e5791ec6518e8df5fc87980fe9e4839924e5f8e6f8d99f3b02dd9352\n",
            "Suspect hash: 7f119862e5791ec6518e8df5fc87980fe9e4839924e5f8e6f8d99f3b02dd9352\n",
            "✅ MATCH: Videos are identical.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AT TOP VIDEO SHOULD GET THE FAKE OR NOT\n"
      ],
      "metadata": {
        "id": "Cz21aJPPNCHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def hash_video_file(file_path):\n",
        "    BUF_SIZE = 65536\n",
        "    sha256 = hashlib.sha256()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        while True:\n",
        "            data = f.read(BUF_SIZE)\n",
        "            if not data:\n",
        "                break\n",
        "            sha256.update(data)\n",
        "    return sha256.hexdigest()\n",
        "\n",
        "# Hash two video files\n",
        "hash1 = hash_video_file('/content/1.mp4')\n",
        "hash2 = hash_video_file('/content/masked video.mp4')\n",
        "\n",
        "print(\"Original hash:\", hash1)\n",
        "print(\"Suspect hash:\", hash2)\n",
        "\n",
        "if hash1 == hash2:\n",
        "    print(\"✅ MATCH: Original video.\")\n",
        "    label_text = \"Original\"\n",
        "    label_color = (0, 255, 0)  # Green\n",
        "else:\n",
        "    print(\"❌ MISMATCH: Masked (fake) video.\")\n",
        "    label_text = \"FAKE\"\n",
        "    label_color = (0, 0, 255)  # Red\n",
        "\n",
        "# Open the suspect video\n",
        "video_path = '/content/masked video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Output video writer\n",
        "output_path = '/content/labeled_output.mp4'\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Add label text\n",
        "    cv2.putText(frame,\n",
        "                label_text,\n",
        "                (50, 50),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1.5,\n",
        "                label_color,\n",
        "                3,\n",
        "                cv2.LINE_AA)\n",
        "\n",
        "    # Write frame to output video\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"✅ Done! Labeled video saved to: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Mux2kWNJ2C",
        "outputId": "a74b3218-3e3d-4681-912f-8df67b85c435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original hash: 7f119862e5791ec6518e8df5fc87980fe9e4839924e5f8e6f8d99f3b02dd9352\n",
            "Suspect hash: e31b5c1caca235d9097662c4d686fa52be96fc12ca715f80597ba4bbb0b1a826\n",
            "❌ MISMATCH: Masked (fake) video.\n",
            "✅ Done! Labeled video saved to: /content/labeled_output.mp4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}